{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyarrow as pa\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tqdm  import tqdm\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anisha/Documents/Booz/bias_project/bias/lib/python3.13/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "sent_and_word=pd.read_excel('labeled_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>Label_bias</th>\n",
       "      <th>Label_opinion</th>\n",
       "      <th>article</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>YouTube is making clear there will be no â€œbirt...</td>\n",
       "      <td>https://eu.usatoday.com/story/tech/2020/02/03/...</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>center</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>YouTube says no â€˜deepfakesâ€™ or â€˜birtherâ€™ video...</td>\n",
       "      <td>['belated', 'birtherism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The increasingly bitter dispute between Americ...</td>\n",
       "      <td>https://www.nbcnews.com/news/sports/women-s-te...</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>sport</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>FRISCO, Texas â€” The increasingly bitter disput...</td>\n",
       "      <td>['bitter']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>https://www.alternet.org/2019/01/here-are-5-of...</td>\n",
       "      <td>alternet</td>\n",
       "      <td>immigration</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writerâ€™s opinion</td>\n",
       "      <td>Speaking to the country for the first time fro...</td>\n",
       "      <td>['crisis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>https://www.breitbart.com/politics/2019/05/09/...</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>['legitimate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>https://thefederalist.com/2020/03/11/woman-who...</td>\n",
       "      <td>federalist</td>\n",
       "      <td>abortion</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>The left has a thing for taking babies hostage...</td>\n",
       "      <td>['killing', 'never', 'developing', 'humans', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           sentence  \\\n",
       "0           0  YouTube is making clear there will be no â€œbirt...   \n",
       "1           1  The increasingly bitter dispute between Americ...   \n",
       "2           2  So while there may be a humanitarian crisis dr...   \n",
       "3           3  A professor who teaches climate change classes...   \n",
       "4           4  Looking around the United States, there is nev...   \n",
       "\n",
       "                                           news_link      outlet  \\\n",
       "0  https://eu.usatoday.com/story/tech/2020/02/03/...   usa-today   \n",
       "1  https://www.nbcnews.com/news/sports/women-s-te...       msnbc   \n",
       "2  https://www.alternet.org/2019/01/here-are-5-of...    alternet   \n",
       "3  https://www.breitbart.com/politics/2019/05/09/...   breitbart   \n",
       "4  https://thefederalist.com/2020/03/11/woman-who...  federalist   \n",
       "\n",
       "            topic    type  group_id  num_sent  Label_bias  \\\n",
       "0  elections-2020  center         1         1      Biased   \n",
       "1           sport    left         1         1  Non-biased   \n",
       "2     immigration    left         1         1      Biased   \n",
       "3     environment   right         1         1  Non-biased   \n",
       "4        abortion   right         1         1      Biased   \n",
       "\n",
       "                           Label_opinion  \\\n",
       "0  Somewhat factual but also opinionated   \n",
       "1                       Entirely factual   \n",
       "2             Expresses writerâ€™s opinion   \n",
       "3                           No agreement   \n",
       "4  Somewhat factual but also opinionated   \n",
       "\n",
       "                                             article  \\\n",
       "0  YouTube says no â€˜deepfakesâ€™ or â€˜birtherâ€™ video...   \n",
       "1  FRISCO, Texas â€” The increasingly bitter disput...   \n",
       "2  Speaking to the country for the first time fro...   \n",
       "3  A professor who teaches climate change classes...   \n",
       "4  The left has a thing for taking babies hostage...   \n",
       "\n",
       "                                        biased_words  \n",
       "0                          ['belated', 'birtherism']  \n",
       "1                                         ['bitter']  \n",
       "2                                         ['crisis']  \n",
       "3                                     ['legitimate']  \n",
       "4  ['killing', 'never', 'developing', 'humans', '...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_and_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=sent_and_word[['sentence', 'Label_bias']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=sent_and_word[['sentence', 'biased_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Label_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no â€œbirt...</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The increasingly bitter dispute between Americ...</td>\n",
       "      <td>Non-biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>Non-biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  Label_bias\n",
       "0  YouTube is making clear there will be no â€œbirt...      Biased\n",
       "1  The increasingly bitter dispute between Americ...  Non-biased\n",
       "2  So while there may be a humanitarian crisis dr...      Biased\n",
       "3  A professor who teaches climate change classes...  Non-biased\n",
       "4  Looking around the United States, there is nev...      Biased"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no â€œbirt...</td>\n",
       "      <td>['belated', 'birtherism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The increasingly bitter dispute between Americ...</td>\n",
       "      <td>['bitter']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>['crisis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>['legitimate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>['killing', 'never', 'developing', 'humans', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  YouTube is making clear there will be no â€œbirt...   \n",
       "1  The increasingly bitter dispute between Americ...   \n",
       "2  So while there may be a humanitarian crisis dr...   \n",
       "3  A professor who teaches climate change classes...   \n",
       "4  Looking around the United States, there is nev...   \n",
       "\n",
       "                                        biased_words  \n",
       "0                          ['belated', 'birtherism']  \n",
       "1                                         ['bitter']  \n",
       "2                                         ['crisis']  \n",
       "3                                     ['legitimate']  \n",
       "4  ['killing', 'never', 'developing', 'humans', '...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=sent[sent['Label_bias'] != 'No agreement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label_bias\n",
       "Biased        1018\n",
       "Non-biased     533\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent['Label_bias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_csv('labeled_dataset_sent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "word.to_csv('labeled_dataset_word.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class_size = sent[sent['Label_bias'] == 'Non-biased'].shape[0]\n",
    "\n",
    "# Sample from majority class\n",
    "majority_downsampled = sent[sent['Label_bias'] == 'Biased'].sample(\n",
    "    n=minority_class_size, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine with minority class\n",
    "sent= pd.concat([\n",
    "    sent[sent['Label_bias'] == 'Non-biased'],\n",
    "    majority_downsampled\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_csv('balanced_dataset_sent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word.to_csv('labeled_dataset_word.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.rename(columns={\"sentence\": \"text\", \"Label_bias\": \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word.rename(columns={\"sentence\": \"text\", \"biased_words\": \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num={'Non-biased': 0, 'Biased': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xq/q8k6p6r524x9md10q7frq9dr0000gn/T/ipykernel_22967/3207431553.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  sent['label']=sent['label'].replace(num)\n"
     ]
    }
   ],
   "source": [
    "sent['label']=sent['label'].replace(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no â€œbirt...</td>\n",
       "      <td>['belated', 'birtherism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The increasingly bitter dispute between Americ...</td>\n",
       "      <td>['bitter']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>['crisis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>['legitimate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>['killing', 'never', 'developing', 'humans', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  YouTube is making clear there will be no â€œbirt...   \n",
       "1  The increasingly bitter dispute between Americ...   \n",
       "2  So while there may be a humanitarian crisis dr...   \n",
       "3  A professor who teaches climate change classes...   \n",
       "4  Looking around the United States, there is nev...   \n",
       "\n",
       "                                        biased_words  \n",
       "0                          ['belated', 'birtherism']  \n",
       "1                                         ['bitter']  \n",
       "2                                         ['crisis']  \n",
       "3                                     ['legitimate']  \n",
       "4  ['killing', 'never', 'developing', 'humans', '...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_dataset_sent = Dataset(pa.Table.from_pandas(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hg_dataset_word = Dataset(pa.Table.from_pandas(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset_sent = hg_dataset_sent.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1066"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shuffled_dataset_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_sent = shuffled_dataset_sent.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 852\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_sent = train_test_split_sent['train']\n",
    "test_dataset_sent = train_test_split_sent['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_pandas=test_dataset_sent.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_pandas.to_csv('test_set_sent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_pandas['label'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6e869832334f5f9f673e8d051f4f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/852 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f259aea1d38a4a9eb06230aee4bcefff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset_sent.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset_sent.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xq/q8k6p6r524x9md10q7frq9dr0000gn/T/ipykernel_22967/1698321876.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='results',\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=4,                    # +1 from your original\n",
    "    per_device_train_batch_size=16,        # Will auto-adjust based on GPU\n",
    "    per_device_eval_batch_size=32,         # Larger for eval (no gradients)\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,                     # Reduced from your 0.05\n",
    "    eval_strategy=\"epoch\",           # Changed from \"epoch\"\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",            # ðŸ”¥ Key change for bias detection\n",
    "    greater_is_better=True,                            # 2x speedup\n",
    "    seed=42,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_test,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 03:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530277</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.785179</td>\n",
       "      <td>0.785448</td>\n",
       "      <td>0.785047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.467261</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>0.762646</td>\n",
       "      <td>0.761682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.482240</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>0.762646</td>\n",
       "      <td>0.761682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499418</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.769108</td>\n",
       "      <td>0.773026</td>\n",
       "      <td>0.771028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=216, training_loss=0.4376838472154405, metrics={'train_runtime': 232.7536, 'train_samples_per_second': 14.642, 'train_steps_per_second': 0.928, 'total_flos': 64067650379664.0, 'train_loss': 0.4376838472154405, 'epoch': 4.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
